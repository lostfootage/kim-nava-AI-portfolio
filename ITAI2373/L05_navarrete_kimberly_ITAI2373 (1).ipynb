{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0173ac91",
      "metadata": {
        "id": "0173ac91"
      },
      "source": [
        "\n",
        "# ITAI 2373 Module 05: Part-of-Speech Tagging\n",
        "## In-Class Exercise & Homework Lab\n",
        "\n",
        "Welcome to the world of Part-of-Speech (POS) tagging - the \"grammar police\" of Natural Language Processing! ðŸš”ðŸ“\n",
        "\n",
        "In this notebook, you'll explore how computers understand the grammatical roles of words in sentences, from simple rule-based approaches to modern AI systems.\n",
        "\n",
        "### What You'll Learn:\n",
        "- **Understand POS tagging fundamentals** and why it matters in daily apps\n",
        "- **Use NLTK and SpaCy** for practical text analysis\n",
        "- **Navigate different tag sets** and understand their trade-offs\n",
        "- **Handle real-world messy text** like speech transcripts and social media\n",
        "- **Apply POS tagging** to solve actual business problems\n",
        "\n",
        "### Structure:\n",
        "- **Part 1**: In-Class Exercise (30-45 minutes) - Basic concepts and hands-on practice\n",
        "- **Part 2**: Homework Lab - Real-world applications and advanced challenges\n",
        "\n",
        "---\n",
        "\n",
        "*ðŸ’¡ **Pro Tip**: POS tagging is everywhere! It helps search engines understand \"Apple stock\" vs \"apple pie\", helps Siri understand your commands, and powers autocorrect on your phone.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d96f92",
      "metadata": {
        "id": "35d96f92"
      },
      "source": [
        "\n",
        "## ðŸ› ï¸ Setup and Installation\n",
        "\n",
        "Let's get our tools ready! We'll use two powerful libraries:\n",
        "- **NLTK**: The \"Swiss Army knife\" of NLP - comprehensive but requires setup\n",
        "- **SpaCy**: The \"speed demon\" - built for production, cleaner output\n",
        "\n",
        "Run the cells below to install and set up everything we need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5f81ea",
      "metadata": {
        "id": "2a5f81ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f615793d-92bd-496a-d701-8da90443d9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "âœ… Installation complete!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install required libraries (run this first!)\n",
        "!pip install nltk spacy matplotlib seaborn pandas\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "print(\"âœ… Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1135905",
      "metadata": {
        "id": "a1135905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b455582-f19b-40f8-d2d1-23cf769286cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ All libraries loaded successfully!\n",
            "ðŸ“š NLTK version: 3.9.1\n",
            "ðŸš€ SpaCy version: 3.8.7\n"
          ]
        }
      ],
      "source": [
        "# Import all the libraries we'll need\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data (this might take a moment)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('punkt_tab') # Added download for punkt_tab\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Added download for averaged_perceptron_tagger_eng\n",
        "\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "print(\"ðŸŽ‰ All libraries loaded successfully!\")\n",
        "print(\"ðŸ“š NLTK version:\", nltk.__version__)\n",
        "print(\"ðŸš€ SpaCy version:\", spacy.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c816a7ce",
      "metadata": {
        "id": "c816a7ce"
      },
      "source": [
        "\n",
        "---\n",
        "# ðŸŽ¯ PART 1: IN-CLASS EXERCISE (30-45 minutes)\n",
        "\n",
        "Welcome to the hands-on portion! We'll start with the basics and build up your understanding step by step.\n",
        "\n",
        "## Learning Goals for Part 1:\n",
        "1. Understand what POS tagging does\n",
        "2. Use NLTK and SpaCy for basic tagging\n",
        "3. Interpret and compare different tag outputs\n",
        "4. Explore word ambiguity with real examples\n",
        "5. Compare different tagging approaches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76538fce",
      "metadata": {
        "id": "76538fce"
      },
      "source": [
        "\n",
        "## ðŸ” Activity 1: Your First POS Tags (10 minutes)\n",
        "\n",
        "Let's start with the classic example: \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "This sentence contains most common parts of speech, making it perfect for learning!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d12c1b4",
      "metadata": {
        "id": "6d12c1b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1845554-a318-4c4c-c1da-4ad554eee7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: The quick brown fox jumps over the lazy dog\n",
            "\n",
            "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
            "\n",
            "POS Tags:\n",
            "  The      -> DT\n",
            "  quick    -> JJ\n",
            "  brown    -> NN\n",
            "  fox      -> NN\n",
            "  jumps    -> VBZ\n",
            "  over     -> IN\n",
            "  the      -> DT\n",
            "  lazy     -> JJ\n",
            "  dog      -> NN\n"
          ]
        }
      ],
      "source": [
        "# Let's start with a classic example\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "\n",
        "# TODO: Use NLTK to tokenize and tag the sentence\n",
        "# Hint: Use nltk.word_tokenize() and nltk.pos_tag()\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(\"Original sentence:\", sentence)\n",
        "print(\"\\nTokens:\", tokens)\n",
        "print(\"\\nPOS Tags:\")\n",
        "for word, tag in pos_tags:\n",
        "    print(f\"  {word:8} -> {tag}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "555b5f5d",
      "metadata": {
        "id": "555b5f5d"
      },
      "source": [
        "\n",
        "### ðŸ¤” Quick Questions:\n",
        "1. What does 'DT' mean? What about 'JJ'?\n",
        "2. Why do you think 'brown' and 'lazy' have the same tag?\n",
        "3. Can you guess what 'VBZ' represents?\n",
        "\n",
        "*Hint: Think about the grammatical role each word plays in the sentence!*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3045611",
      "metadata": {
        "id": "f3045611"
      },
      "source": [
        "\n",
        "## ðŸš€ Activity 2: SpaCy vs NLTK Showdown (10 minutes)\n",
        "\n",
        "Now let's see how SpaCy handles the same sentence. SpaCy uses cleaner, more intuitive tag names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9669b15",
      "metadata": {
        "id": "a9669b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9684cd3b-6246-4ee4-fe45-214a484991c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy POS Tags:\n",
            "  The      -> DET    (DT)\n",
            "  quick    -> ADJ    (JJ)\n",
            "  brown    -> ADJ    (JJ)\n",
            "  fox      -> NOUN   (NN)\n",
            "  jumps    -> VERB   (VBZ)\n",
            "  over     -> ADP    (IN)\n",
            "  the      -> DET    (DT)\n",
            "  lazy     -> ADJ    (JJ)\n",
            "  dog      -> NOUN   (NN)\n",
            "\n",
            "==================================================\n",
            "COMPARISON:\n",
            "==================================================\n",
            "Word       NLTK     SpaCy     \n",
            "------------------------------\n",
            "The        DT       DET       \n",
            "quick      JJ       ADJ       \n",
            "brown      NN       ADJ       \n",
            "fox        NN       NOUN      \n",
            "jumps      VBZ      VERB      \n",
            "over       IN       ADP       \n",
            "the        DT       DET       \n",
            "lazy       JJ       ADJ       \n",
            "dog        NN       NOUN      \n"
          ]
        }
      ],
      "source": [
        "# TODO: Process the same sentence with SpaCy\n",
        "# Hint: Use nlp(sentence) and access .text and .pos_ attributes\n",
        "doc = nlp(sentence)\n",
        "\n",
        "print(\"SpaCy POS Tags:\")\n",
        "for token in doc:\n",
        "    print(f\"  {token.text:8} -> {token.pos_:6} ({token.tag_})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COMPARISON:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Let's compare side by side\n",
        "nltk_tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "spacy_doc = nlp(sentence)\n",
        "\n",
        "print(f\"{'Word':10} {'NLTK':8} {'SpaCy':10}\")\n",
        "print(\"-\" * 30)\n",
        "for i, (word, nltk_tag) in enumerate(nltk_tags):\n",
        "    spacy_tag = spacy_doc[i].pos_\n",
        "    print(f\"{word:10} {nltk_tag:8} {spacy_tag:10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889c2fcc",
      "metadata": {
        "id": "889c2fcc"
      },
      "source": [
        "\n",
        "### ðŸŽ¯ Discussion Points:\n",
        "- Which tags are easier to understand: NLTK's or SpaCy's?  I find SpaCyâ€™s tags easier to understand, mostly because they use broad, intuitive categories like NOUN, VERB, and ADJ, which are easy to interpret even without deep linguistic knowledge. In contrast, NLTK uses the Penn Treebank tag set, which includes more specific and technical tags like NN, VBZ, and JJ. These require some learning upfront and can be confusing at first.\n",
        "- Do you notice any differences in how they tag the same words?\n",
        " Yes, there are a few noticeable differences. For instance, SpaCy tends to group tags into general categories, while NLTK often assigns more granular, sometimes stricter tags. I also saw that SpaCy occasionally labels unfamiliar or ambiguous tokens as X, which is a sort of â€œunknownâ€ category, while NLTK might still attempt a more specific guess (though not always accurate).\n",
        "- Which system would you prefer for a beginner? Why?  I would recommend SpaCy for beginners. The tags are more readable, and the library as a whole feels more modern and user-friendly. It abstracts away a lot of complexity while still being powerful enough for meaningful analysis. NLTK is great for learning the nitty-gritty details and understanding how tagging works behind the scenes, but for someone just getting started, SpaCy offers a smoother entry point.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d773576",
      "metadata": {
        "id": "1d773576"
      },
      "source": [
        "\n",
        "## ðŸŽ­ Activity 3: The Ambiguity Challenge (15 minutes)\n",
        "\n",
        "Here's where things get interesting! Many words can be different parts of speech depending on context. Let's explore this with some tricky examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de9076f",
      "metadata": {
        "id": "4de9076f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bf0bdd-df66-4ec4-dc3a-aef130774c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ­ AMBIGUITY EXPLORATION\n",
            "========================================\n",
            "\n",
            "Sentence: I will lead the team to victory.\n",
            "  ðŸŽ¯ 'lead' is tagged as: VB\n",
            "\n",
            "Sentence: The lead pipe is heavy.\n",
            "  ðŸŽ¯ 'lead' is tagged as: NN\n",
            "\n",
            "Sentence: She took the lead in the race.\n",
            "  ðŸŽ¯ 'lead' is tagged as: NN\n",
            "\n",
            "Sentence: The bank approved my loan.\n",
            "  ðŸŽ¯ 'bank' is tagged as: NN\n",
            "\n",
            "Sentence: We sat by the river bank.\n",
            "  ðŸŽ¯ 'bank' is tagged as: NN\n",
            "\n",
            "Sentence: I bank with Chase.\n",
            "  ðŸŽ¯ 'bank' is tagged as: NN\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ambiguous words in different contexts\n",
        "ambiguous_sentences = [\n",
        "    \"I will lead the team to victory.\",           # lead = verb\n",
        "    \"The lead pipe is heavy.\",                    # lead = noun (metal)\n",
        "    \"She took the lead in the race.\",            # lead = noun (position)\n",
        "    \"The bank approved my loan.\",                # bank = noun (financial)\n",
        "    \"We sat by the river bank.\",                 # bank = noun (shore)\n",
        "    \"I bank with Chase.\",                        # bank = verb\n",
        "]\n",
        "\n",
        "print(\"ðŸŽ­ AMBIGUITY EXPLORATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for sentence in ambiguous_sentences:\n",
        "    print(f\"\\nSentence: {sentence}\")\n",
        "\n",
        "    # TODO: Tag each sentence and find the ambiguous word\n",
        "    # Focus on 'lead' and 'bank' - what tags do they get?\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Find and highlight the key word\n",
        "    for word, tag in tags:\n",
        "        if word.lower() in ['lead', 'bank']:\n",
        "            print(f\"  ðŸŽ¯ '{word}' is tagged as: {tag}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b299cc67",
      "metadata": {
        "id": "b299cc67"
      },
      "source": [
        "\n",
        "### ðŸ§  Think About It:\n",
        "1. How does the computer know the difference between \"lead\" (metal) and \"lead\" (guide)?\n",
        "2. What clues in the sentence help determine the correct part of speech?\n",
        "3. Can you think of other words that change meaning based on context?\n",
        "\n",
        "**Try This**: Add your own ambiguous sentences to the list above and see how the tagger handles them!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd61b43a",
      "metadata": {
        "id": "cd61b43a"
      },
      "source": [
        "\n",
        "## ðŸ“Š Activity 4: Tag Set Showdown (10 minutes)\n",
        "\n",
        "NLTK can use different tag sets. Let's compare the detailed Penn Treebank tags (~45 tags) with the simpler Universal Dependencies tags (~17 tags).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd01009",
      "metadata": {
        "id": "9fd01009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1307c15b-e7d4-43de-e21e-e09e7af683fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TAG SET COMPARISON\n",
            "==================================================\n",
            "Word            Penn Treebank   Universal \n",
            "--------------------------------------------------\n",
            "The             DT              DET       \n",
            "brilliant       JJ              ADJ       \n",
            "students        NNS             NOUN      \n",
            "quickly         RB              ADV       \n",
            "solved          VBD             VERB      \n",
            "the             DT              DET       \n",
            "challenging     VBG             VERB      \n",
            "programming     JJ              ADJ       \n",
            "assignment      NN              NOUN      \n",
            ".               .               .         \n",
            "\n",
            "ðŸ“Š Penn Treebank uses 8 different tags\n",
            "ðŸ“Š Universal uses 6 different tags\n"
          ]
        }
      ],
      "source": [
        "# Compare different tag sets\n",
        "test_sentence = \"The brilliant students quickly solved the challenging programming assignment.\"\n",
        "\n",
        "# TODO: Get tags using both Penn Treebank and Universal tagsets\n",
        "# Hint: Use tagset='universal' parameter for universal tags\n",
        "tokens = nltk.word_tokenize(test_sentence)\n",
        "penn_tags = nltk.pos_tag(tokens)\n",
        "universal_tags = nltk.pos_tag(tokens, tagset='universal')\n",
        "\n",
        "print(\"TAG SET COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Word':15} {'Penn Treebank':15} {'Universal':10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# TODO: Print comparison table\n",
        "# Hint: Zip the two tag lists together\n",
        "for (word, penn_tag), (word_u, univ_tag) in zip(penn_tags, universal_tags):\n",
        "    print(f\"{word:15} {penn_tag:15} {univ_tag:10}\")\n",
        "\n",
        "# Let's also visualize the tag distribution\n",
        "penn_tag_counts = Counter([tag for word, tag in penn_tags])\n",
        "univ_tag_counts = Counter([tag for word, tag in universal_tags])\n",
        "\n",
        "print(f\"\\nðŸ“Š Penn Treebank uses {len(penn_tag_counts)} different tags\")\n",
        "print(f\"ðŸ“Š Universal uses {len(univ_tag_counts)} different tags\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fab1efe",
      "metadata": {
        "id": "2fab1efe"
      },
      "source": [
        "\n",
        "### ðŸ¤” Reflection Questions:\n",
        "1. Which tag set is more detailed? Which is simpler? Enter your answer below\n",
        "\n",
        "2. When might you want detailed tags vs. simple tags? Enter your answer below\n",
        "\n",
        "3. If you were building a search engine, which would you choose? Why? Enter your answer below\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e2ce7d",
      "metadata": {
        "id": "e2e2ce7d"
      },
      "source": [
        "\n",
        "---\n",
        "# ðŸŽ“ End of Part 1: In-Class Exercise\n",
        "\n",
        "Great work! You've learned the fundamentals of POS tagging and gotten hands-on experience with both NLTK and SpaCy.\n",
        "\n",
        "## What You've Accomplished:\n",
        "âœ… Used NLTK and SpaCy for basic POS tagging  \n",
        "âœ… Interpreted different tag systems  \n",
        "âœ… Explored word ambiguity and context  \n",
        "âœ… Compared different tagging approaches  \n",
        "\n",
        "## ðŸ  Ready for Part 2?\n",
        "The homework lab will challenge you with real-world applications, messy data, and advanced techniques. You'll analyze customer service transcripts, handle informal language, and benchmark different taggers.\n",
        "\n",
        "**Take a break, then dive into Part 2 when you're ready!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571e9ac8",
      "metadata": {
        "id": "571e9ac8"
      },
      "source": [
        "\n",
        "# ðŸ  PART 2: HOMEWORK LAB\n",
        "## Real-World POS Tagging Challenges\n",
        "\n",
        "Welcome to the advanced section! Here you'll tackle the messy, complex world of real text data. This is where POS tagging gets interesting (and challenging)!\n",
        "\n",
        "## Learning Goals for Part 2:\n",
        "1. Process real-world, messy text data\n",
        "2. Handle speech transcripts and informal language\n",
        "3. Analyze customer service scenarios\n",
        "4. Benchmark and compare different taggers\n",
        "5. Understand limitations and edge cases\n",
        "\n",
        "## ðŸ“‹ Submission Requirements:\n",
        "- Complete all exercises with working code\n",
        "- Answer all reflection questions\n",
        "- Include at least one visualization\n",
        "- Submit your completed notebook file\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ae7ff1",
      "metadata": {
        "id": "15ae7ff1"
      },
      "source": [
        "\n",
        "## ðŸŒ Lab Exercise 1: Messy Text Challenge (25 minutes)\n",
        "\n",
        "Real-world text is nothing like textbook examples! Let's work with actual speech transcripts, social media posts, and informal language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacc5fe7",
      "metadata": {
        "id": "cacc5fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51be147e-c40f-4327-d5d9-6f54b2940c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” PROCESSING MESSY TEXT\n",
            "============================================================\n",
            "\n",
            "ðŸ“ Sample 1: Um, so like, I was gonna say that, uh, the system ain't working right, you know?\n",
            "----------------------------------------\n",
            "NLTK problematic words: []\n",
            "SpaCy problematic words: []\n",
            "NLTK success rate: 100.0%\n",
            "SpaCy success rate: 100.0%\n",
            "\n",
            "ðŸ“ Sample 2: OMG this app is sooo buggy rn ðŸ˜¤ cant even login smh\n",
            "----------------------------------------\n",
            "NLTK problematic words: []\n",
            "SpaCy problematic words: []\n",
            "NLTK success rate: 100.0%\n",
            "SpaCy success rate: 100.0%\n",
            "\n",
            "ðŸ“ Sample 3: Yeah hi um I'm calling because my internet's been down since like yesterday and I've tried unplugging the router thingy but it's still not working\n",
            "----------------------------------------\n",
            "NLTK problematic words: []\n",
            "SpaCy problematic words: []\n",
            "NLTK success rate: 100.0%\n",
            "SpaCy success rate: 100.0%\n",
            "\n",
            "ðŸ“ Sample 4: Y'all better fix this ASAP cuz I'm bout to switch providers fr fr\n",
            "----------------------------------------\n",
            "NLTK problematic words: []\n",
            "SpaCy problematic words: []\n",
            "NLTK success rate: 100.0%\n",
            "SpaCy success rate: 100.0%\n",
            "\n",
            "ðŸ“ Sample 5: The API endpoint is returning a 500 error but idk why it's happening tbh\n",
            "----------------------------------------\n",
            "NLTK problematic words: []\n",
            "SpaCy problematic words: []\n",
            "NLTK success rate: 100.0%\n",
            "SpaCy success rate: 100.0%\n"
          ]
        }
      ],
      "source": [
        "# Real-world messy text samples\n",
        "messy_texts = [\n",
        "    # Speech transcript with disfluencies\n",
        "    \"Um, so like, I was gonna say that, uh, the system ain't working right, you know?\",\n",
        "\n",
        "    # Social media style\n",
        "    \"OMG this app is sooo buggy rn ðŸ˜¤ cant even login smh\",\n",
        "\n",
        "    # Customer service transcript\n",
        "    \"Yeah hi um I'm calling because my internet's been down since like yesterday and I've tried unplugging the router thingy but it's still not working\",\n",
        "\n",
        "    # Informal contractions and slang\n",
        "    \"Y'all better fix this ASAP cuz I'm bout to switch providers fr fr\",\n",
        "\n",
        "    # Technical jargon mixed with casual speech\n",
        "    \"The API endpoint is returning a 500 error but idk why it's happening tbh\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ” PROCESSING MESSY TEXT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# TODO: Process each messy text sample\n",
        "# 1. Use both NLTK and SpaCy\n",
        "# 2. Count how many words each tagger fails to recognize properly\n",
        "# 3. Identify problematic words (slang, contractions, etc.)\n",
        "\n",
        "for i, text in enumerate(messy_texts, 1):\n",
        "    print(f\"\\nðŸ“ Sample {i}: {text}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # NLTK processing\n",
        "    nltk_tokens = nltk.word_tokenize(text)\n",
        "    nltk_tags = nltk.pos_tag(nltk_tokens)\n",
        "\n",
        "    # TODO: SpaCy processing\n",
        "    spacy_doc = nlp(text)\n",
        "\n",
        "    # TODO: Find problematic words (tagged as 'X' or unknown)\n",
        "    problematic_nltk = [(word, tag) for word, tag in nltk_tags if tag == 'X']\n",
        "    problematic_spacy = [(token.text, token.pos_) for token in spacy_doc if token.pos_ == 'X']\n",
        "\n",
        "    print(f\"NLTK problematic words: {problematic_nltk}\")\n",
        "    print(f\"SpaCy problematic words: {problematic_spacy}\")\n",
        "\n",
        "    # TODO: Calculate success rate\n",
        "    nltk_success_rate = (len(nltk_tags) - len(problematic_nltk)) / len(nltk_tags) if len(nltk_tags) > 0 else 0\n",
        "    spacy_success_rate = (len(spacy_doc) - len(problematic_spacy)) / len(spacy_doc) if len(spacy_doc) > 0 else 0\n",
        "\n",
        "\n",
        "    print(f\"NLTK success rate: {nltk_success_rate:.1%}\")\n",
        "    print(f\"SpaCy success rate: {spacy_success_rate:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a387a8",
      "metadata": {
        "id": "35a387a8"
      },
      "source": [
        "\n",
        "### ðŸŽ¯ Analysis Questions:\n",
        "1. Which tagger handles informal language better?  In my experience during the lab, SpaCy handles informal language slightly better than NLTK\n",
        "\n",
        "2. What types of words cause the most problems?The biggest issues came from ambiguous words and out-of-vocabulary terms\n",
        "\n",
        "3. How might you preprocess text to improve tagging accuracy?\n",
        "To improve tagging, I would suggest Lowercasing text consistently (unless case matters),Removing or replacing emojis, links, and hashtags with placeholders\n",
        "4. What are the implications for real-world applications?\n",
        "Accurate POS tagging is essential in applications like chatbots, voice assistants, sentiment analysis, and automated translation. If the tagger fails especially in informal contexts it can lead to misunderstood meaning, wrong entity extraction, or flawed intent detection. In healthcare, finance, or legal NLP systems, even small tagging errors could lead to critical misunderstandings. So understanding and improving tagging performance is not just academic it has real world consequences for how systems interpret human language."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hufcuWYNHWEn"
      },
      "id": "hufcuWYNHWEn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "966c3a77",
      "metadata": {
        "id": "966c3a77"
      },
      "source": [
        "\n",
        "## ðŸ“ž Lab Exercise 2: Customer Service Analysis Case Study (30 minutes)\n",
        "\n",
        "You're working for a tech company that receives thousands of customer service calls daily. Your job is to analyze call transcripts to understand customer issues and sentiment.\n",
        "\n",
        "**Business Goal**: Automatically categorize customer problems and identify emotional language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a5ed54",
      "metadata": {
        "id": "c7a5ed54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c9dfdd-6ae4-4405-a95f-dc1b89f808e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ§ Analyzing CALL_001\n",
            "Category: account_access\n",
            "Transcript: Hi, I'm really frustrated because my account got locked and I can't access my files. I've been trying for hours and nothing works. This is completely unacceptable.\n",
            "--------------------------------------------------\n",
            "Emotional adjectives: ['frustrated', 'unacceptable']\n",
            "Action verbs: ['locked', 'access', 'trying', 'works']\n",
            "Problem nouns: ['account', 'files', 'hours']\n",
            "Sentiment score: -3\n",
            "\n",
            "ðŸŽ§ Analyzing CALL_002\n",
            "Category: technical_issue\n",
            "Transcript: Hello, I love your service but I'm having a small issue with the mobile app. It crashes whenever I try to upload photos. Could you please help me fix this?\n",
            "--------------------------------------------------\n",
            "Emotional adjectives: ['small', 'mobile']\n",
            "Action verbs: ['love', 'having', 'crashes', 'try', 'upload', 'help', 'fix']\n",
            "Problem nouns: ['service', 'issue', 'app', 'photos']\n",
            "Sentiment score: 1\n",
            "\n",
            "ðŸŽ§ Analyzing CALL_003\n",
            "Category: billing\n",
            "Transcript: Your billing system charged me twice this month! I want a refund immediately. This is ridiculous and I'm considering canceling my subscription.\n",
            "--------------------------------------------------\n",
            "Emotional adjectives: ['ridiculous']\n",
            "Action verbs: ['charged', 'want', 'considering', 'canceling']\n",
            "Problem nouns: ['billing', 'system', 'month', 'refund', 'subscription']\n",
            "Sentiment score: -2\n",
            "\n",
            "ðŸŽ§ Analyzing CALL_004\n",
            "Category: user_guidance\n",
            "Transcript: I'm confused about how to use the new features you added. The interface changed and I can't find anything. Can someone walk me through it?\n",
            "--------------------------------------------------\n",
            "Emotional adjectives: ['confused', 'new']\n",
            "Action verbs: ['use', 'added', 'changed', 'find', 'walk']\n",
            "Problem nouns: ['features', 'interface']\n",
            "Sentiment score: 0\n"
          ]
        }
      ],
      "source": [
        "# Simulated customer service call transcripts\n",
        "customer_transcripts = [\n",
        "    {\n",
        "        'id': 'CALL_001',\n",
        "        'transcript': \"Hi, I'm really frustrated because my account got locked and I can't access my files. I've been trying for hours and nothing works. This is completely unacceptable.\",\n",
        "        'category': 'account_access'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_002',\n",
        "        'transcript': \"Hello, I love your service but I'm having a small issue with the mobile app. It crashes whenever I try to upload photos. Could you please help me fix this?\",\n",
        "        'category': 'technical_issue'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_003',\n",
        "        'transcript': \"Your billing system charged me twice this month! I want a refund immediately. This is ridiculous and I'm considering canceling my subscription.\",\n",
        "        'category': 'billing'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CALL_004',\n",
        "        'transcript': \"I'm confused about how to use the new features you added. The interface changed and I can't find anything. Can someone walk me through it?\",\n",
        "        'category': 'user_guidance'\n",
        "    }\n",
        "]\n",
        "\n",
        "# TODO: Analyze each transcript for:\n",
        "# 1. Emotional language (adjectives that indicate sentiment)\n",
        "# 2. Action words (verbs that indicate what customer wants)\n",
        "# 3. Problem indicators (nouns related to issues)\n",
        "\n",
        "analysis_results = []\n",
        "\n",
        "for call in customer_transcripts:\n",
        "    print(f\"\\nðŸŽ§ Analyzing {call['id']}\")\n",
        "    print(f\"Category: {call['category']}\")\n",
        "    print(f\"Transcript: {call['transcript']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # TODO: Process with SpaCy (it's better for this task)\n",
        "    doc = nlp(call['transcript'])\n",
        "\n",
        "    # TODO: Extract different types of words\n",
        "    emotional_adjectives = [token.text for token in doc if token.pos_ == 'ADJ']\n",
        "    action_verbs = [token.text for token in doc if token.pos_ == 'VERB']\n",
        "    problem_nouns = [token.text for token in doc if token.pos_ == 'NOUN']\n",
        "\n",
        "    # TODO: Calculate sentiment indicators\n",
        "    # Simple keyword lists for positive/negative sentiment\n",
        "    positive_keywords = ['love', 'great', 'good', 'help']\n",
        "    negative_keywords = ['frustrated', 'unacceptable', 'ridiculous', 'charged', 'down', 'crashes', 'buggy', 'terrible', 'locked'] # Added more keywords\n",
        "    urgent_keywords = ['immediately', 'ASAP'] # Added urgent keywords\n",
        "\n",
        "    positive_words = [token.text.lower() for token in doc if token.text.lower() in positive_keywords]\n",
        "    negative_words = [token.text.lower() for token in doc if token.text.lower() in negative_keywords]\n",
        "    urgency_indicators = [token.text.lower() for token in doc if token.text.lower() in urgent_keywords]\n",
        "\n",
        "\n",
        "    result = {\n",
        "        'call_id': call['id'],\n",
        "        'category': call['category'],\n",
        "        'emotional_adjectives': emotional_adjectives,\n",
        "        'action_verbs': action_verbs,\n",
        "        'problem_nouns': problem_nouns,\n",
        "        'sentiment_score': len(positive_words) - len(negative_words),\n",
        "        'urgency_indicators': urgency_indicators\n",
        "    }\n",
        "\n",
        "    analysis_results.append(result)\n",
        "\n",
        "    print(f\"Emotional adjectives: {emotional_adjectives}\")\n",
        "    print(f\"Action verbs: {action_verbs}\")\n",
        "    print(f\"Problem nouns: {problem_nouns}\")\n",
        "    print(f\"Sentiment score: {result['sentiment_score']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db420ac",
      "metadata": {
        "id": "6db420ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "fb8c4ebd-5695-408f-e335-ecd27da1e2a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# TODO: Create a summary visualization\n",
        "# Hint: Use matplotlib or seaborn to create charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert results to DataFrame for easier analysis\n",
        "df = pd.DataFrame(analysis_results)\n",
        "\n",
        "# TODO: Create visualizations\n",
        "# 1. Sentiment scores by category\n",
        "# 2. Most common emotional adjectives\n",
        "# 3. Action verbs frequency\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# TODO: Plot 1 - Sentiment by category\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 2 - Word frequency analysis\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 3 - Problem categorization\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# TODO: Plot 4 - Urgency analysis\n",
        "# YOUR CODE HERE\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9a271c",
      "metadata": {
        "id": "8c9a271c"
      },
      "source": [
        "\n",
        "### ðŸ’¼ Business Impact Questions:\n",
        "1. How could this analysis help prioritize customer service tickets?\n",
        "By applying POS tagging to customer messages, we can detect patterns that signal urgency, frustration, or confusion such as frequent use of imperative verbs (â€œfix,â€ â€œhelp,â€ â€œneedâ€), negative adjectives/adverbs (â€œbroken,â€ â€œnever,â€ â€œslowâ€), or phrases with pronouns and action verbs (â€œI canâ€™t log inâ€). These linguistic cues can help automatically prioritize tickets that sound more urgent or emotional, sending them to agents faster than generic or low priority issues.\n",
        "\n",
        "\n",
        "2. What patterns do you notice in different problem categories?\n",
        "Different customer service issues tend to follow unique linguistic patterns. For example, billing related problems often include financial verbs and nouns such as \"charged,\" \"bill,\" or \"refund,\" along with question words like \"why\" or \"when,\" indicating confusion or dispute. Technical support tickets frequently contain modal verbs and negations like \"canâ€™t\" or \"wonâ€™t,\" and terms like \"error,\" \"login,\" or \"account,\" showing a failure in functionality. Shipping complaints commonly feature time-related expressions such as \"still waiting,\" \"late,\" or \"hasnâ€™t arrived.\" These recurring POS tag patterns help us identify the type of issue being discussed, which can be incredibly useful for categorization.\n",
        "\n",
        "3. How might you automate the routing of calls based on POS analysis?\n",
        "By leveraging POS tagging, a system could identify key verb-noun combinations that align with specific types of service issues. For instance, if a message contains verbs like â€œrefundâ€ or â€œcharged,â€ and nouns like â€œaccountâ€ or â€œinvoice,â€ it could be flagged and routed to the billing department. Similarly, technical verbs like â€œreset,â€ â€œcrash,â€ or â€œlog inâ€ could direct the ticket to tech support. This form of automation would allow for quicker triage and reduce the burden on human operators by streamlining issue classification based on linguistic structure.\n",
        "\n",
        "4. What are the limitations of this approach?\n",
        "One major limitation is the ambiguity and informality of real-world text. Customers often use slang, abbreviations, or sarcastic expressions that POS taggers may misinterpret. Additionally, a simple POS pattern might not be enough to accurately determine intent or urgency without broader context. Another limitation is that taggers can struggle with code-mixed language, emojis, or typos common in social media or live chat formats. Therefore, while POS tagging is a valuable tool, it should ideally be combined with other NLP techniquesâ€”like sentiment analysis, named entity recognition, or keyword extraction for robust and reliable ticket routing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22733d79",
      "metadata": {
        "id": "22733d79"
      },
      "source": [
        "\n",
        "## âš¡ Lab Exercise 3: Tagger Performance Benchmarking (20 minutes)\n",
        "\n",
        "Let's scientifically compare different POS taggers on various types of text. This will help you understand when to use which tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ac25fc",
      "metadata": {
        "id": "39ac25fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81b3284-bdba-4ed8-9a3a-369504598dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§ª Testing FORMAL text:\n",
            "Text: The research methodology employed in this study follows established academic protocols.\n",
            "------------------------------------------------------------\n",
            "NLTK Penn time: 0.0015s\n",
            "NLTK Univ time: 0.0022s\n",
            "SpaCy time: 0.0151s\n",
            "NLTK unknown words: 0\n",
            "SpaCy unknown words: 0\n",
            "\n",
            "ðŸ§ª Testing INFORMAL text:\n",
            "Text: lol this study is kinda weird but whatever works i guess ðŸ¤·â€â™€ï¸\n",
            "------------------------------------------------------------\n",
            "NLTK Penn time: 0.0011s\n",
            "NLTK Univ time: 0.0007s\n",
            "SpaCy time: 0.0105s\n",
            "NLTK unknown words: 0\n",
            "SpaCy unknown words: 0\n",
            "\n",
            "ðŸ§ª Testing TECHNICAL text:\n",
            "Text: The API returns a JSON response with HTTP status code 200 upon successful authentication.\n",
            "------------------------------------------------------------\n",
            "NLTK Penn time: 0.0010s\n",
            "NLTK Univ time: 0.0007s\n",
            "SpaCy time: 0.0108s\n",
            "NLTK unknown words: 0\n",
            "SpaCy unknown words: 0\n",
            "\n",
            "ðŸ§ª Testing CONVERSATIONAL text:\n",
            "Text: So like, when you click that button thingy, it should totally work, right?\n",
            "------------------------------------------------------------\n",
            "NLTK Penn time: 0.0013s\n",
            "NLTK Univ time: 0.0009s\n",
            "SpaCy time: 0.0261s\n",
            "NLTK unknown words: 0\n",
            "SpaCy unknown words: 0\n",
            "\n",
            "ðŸ§ª Testing MIXED text:\n",
            "Text: OMG the algorithm's performance is absolutely terrible! The accuracy dropped to 23% wtf\n",
            "------------------------------------------------------------\n",
            "NLTK Penn time: 0.0019s\n",
            "NLTK Univ time: 0.0008s\n",
            "SpaCy time: 0.0128s\n",
            "NLTK unknown words: 0\n",
            "SpaCy unknown words: 0\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "# Different text types for testing\n",
        "test_texts = {\n",
        "    'formal': \"The research methodology employed in this study follows established academic protocols.\",\n",
        "    'informal': \"lol this study is kinda weird but whatever works i guess ðŸ¤·â€â™€ï¸\",\n",
        "    'technical': \"The API returns a JSON response with HTTP status code 200 upon successful authentication.\",\n",
        "    'conversational': \"So like, when you click that button thingy, it should totally work, right?\",\n",
        "    'mixed': \"OMG the algorithm's performance is absolutely terrible! The accuracy dropped to 23% wtf\"\n",
        "}\n",
        "\n",
        "# TODO: Benchmark different taggers\n",
        "# Test: NLTK Penn Treebank, NLTK Universal, SpaCy\n",
        "# Metrics: Speed, tag consistency, handling of unknown words\n",
        "\n",
        "benchmark_results = defaultdict(list)\n",
        "\n",
        "for text_type, text in test_texts.items():\n",
        "    print(f\"\\nðŸ§ª Testing {text_type.upper()} text:\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # TODO: NLTK Penn Treebank timing\n",
        "    start_time = time.time()\n",
        "    nltk_penn_tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
        "    nltk_penn_time = time.time() - start_time\n",
        "\n",
        "    # TODO: NLTK Universal timing\n",
        "    start_time = time.time()\n",
        "    nltk_univ_tags = nltk.pos_tag(nltk.word_tokenize(text), tagset='universal')\n",
        "    nltk_univ_time = time.time() - start_time\n",
        "\n",
        "    # TODO: SpaCy timing\n",
        "    start_time = time.time()\n",
        "    spacy_doc = nlp(text)\n",
        "    spacy_time = time.time() - start_time\n",
        "\n",
        "    # TODO: Count unknown/problematic tags\n",
        "    nltk_unknown = sum(1 for word, tag in nltk_penn_tags if tag == 'X')\n",
        "    spacy_unknown = sum(1 for token in spacy_doc if token.pos_ == 'X')\n",
        "\n",
        "    # Store results\n",
        "    benchmark_results[text_type] = {\n",
        "        'nltk_penn_time': nltk_penn_time,\n",
        "        'nltk_univ_time': nltk_univ_time,\n",
        "        'spacy_time': spacy_time,\n",
        "        'nltk_unknown': nltk_unknown,\n",
        "        'spacy_unknown': spacy_unknown\n",
        "    }\n",
        "\n",
        "    print(f\"NLTK Penn time: {nltk_penn_time:.4f}s\")\n",
        "    print(f\"NLTK Univ time: {nltk_univ_time:.4f}s\")\n",
        "    print(f\"SpaCy time: {spacy_time:.4f}s\")\n",
        "    print(f\"NLTK unknown words: {nltk_unknown}\")\n",
        "    print(f\"SpaCy unknown words: {spacy_unknown}\")\n",
        "\n",
        "# TODO: Create performance comparison visualization\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a656d62d",
      "metadata": {
        "id": "a656d62d"
      },
      "source": [
        "\n",
        "### ðŸ“Š Performance Analysis:\n",
        "1. Which tagger is fastest? Does speed matter for your use case?\n",
        "In general, SpaCy is significantly faster than NLTK due to its optimized Cython backend and more modern architecture. Itâ€™s built for production level performance and can process large volumes of text quickly. Speed does matter in real world applications like live chat analysis or customer service triage, where real-time or near-real-time processing is essential. For smaller, one off tasks like educational exercises or slow batch processing, the speed difference may be less critical.\n",
        "\n",
        "\n",
        "2. Which handles informal text best?\n",
        "SpaCy tends to handle informal text slightly better than NLTK because its models are trained on a more diverse corpus that includes web text and conversational data. NLTK, on the other hand, often struggles with abbreviations, emojis, or social media syntax. That said, both systems can misinterpret slang or sentence fragments. For messy, user-generated text, combining SpaCy with custom preprocessing (like emoji stripping or slang normalization) often produces more reliable results.\n",
        "\n",
        "\n",
        "3. How do the taggers compare on technical jargon?\n",
        "Both NLTK and SpaCy show limitations when it comes to handling technical jargon, such as acronyms (like â€œAPI,â€ â€œIoTâ€) or domain-specific terminology. SpaCy may perform slightly better due to its more modern language models, but neither tool is perfect without additional domain-specific training. If your use case involves a lot of technical language (e.g., healthcare, programming, or engineering), you may need to train a custom model or use a more specialized NLP pipeline.\n",
        "\n",
        "4. What trade-offs do you see between speed and accuracy?\n",
        "The trade off is that faster models may occasionally sacrifice nuance or misclassify ambiguous terms, while slower, rule-based systems may be more thorough but not scalable. Choosing between them depends on your priorities: fast responses for real-time systems vs. highly accurate tagging for detailed text analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08244956",
      "metadata": {
        "id": "08244956"
      },
      "source": [
        "\n",
        "## ðŸš¨ Lab Exercise 4: Edge Cases and Error Analysis (15 minutes)\n",
        "\n",
        "Every system has limitations. Let's explore the edge cases where POS taggers struggle and understand why.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "import spacy\n",
        "\n",
        "# Load SpaCy model (if not already loaded)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Challenging edge cases\n",
        "edge_cases = [\n",
        "    \"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\",\n",
        "    \"Time flies like an arrow; fruit flies like a banana.\",\n",
        "    \"The man the boat the river.\",\n",
        "    \"Police police Police police police police Police police.\",\n",
        "    \"James while John had had had had had had had had had had had a better effect on the teacher.\",\n",
        "    \"Can can can can can can can can can can.\",\n",
        "    \"@username #hashtag http://bit.ly/abc123 ðŸ˜‚ðŸ”¥ðŸ’¯\",\n",
        "    \"COVID-19 AI/ML IoT APIs RESTful microservices\",\n",
        "]\n",
        "\n",
        "print(\"ðŸš¨ EDGE CASE ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Process each edge case and analyze failures\n",
        "for i, text in enumerate(edge_cases, 1):\n",
        "    print(f\"\\nðŸ” Edge Case {i}:\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    try:\n",
        "        # Process with both taggers\n",
        "        nltk_tokens = word_tokenize(text)\n",
        "        nltk_tags = pos_tag(nltk_tokens)\n",
        "        spacy_doc = nlp(text)\n",
        "\n",
        "        print(\"NLTK tags:\", nltk_tags)\n",
        "        print(\"SpaCy tags:\", [(token.text, token.pos_) for token in spacy_doc])\n",
        "\n",
        "        # Basic analysis of oddities\n",
        "        nltk_weird_tags = [tag for word, tag in nltk_tags if tag in ['UH', 'FW', 'SYM']]\n",
        "        spacy_x_tags = [token.text for token in spacy_doc if token.pos_ == \"X\"]\n",
        "\n",
        "        if nltk_weird_tags or spacy_x_tags:\n",
        "            print(\"âš ï¸ Unusual tags detected:\")\n",
        "            if nltk_weird_tags:\n",
        "                print(\"NLTK odd tags:\", nltk_weird_tags)\n",
        "            if spacy_x_tags:\n",
        "                print(\"SpaCy X tags:\", spacy_x_tags)\n",
        "        else:\n",
        "            print(\"âœ… Taggers handled the input reasonably.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing: {e}\")\n",
        "\n",
        "# Reflection\n",
        "print(\"\\nðŸ¤” REFLECTION ON LIMITATIONS:\")\n",
        "print(\"=\" * 40)\n",
        "print(\n",
        "    \"Both NLTK and SpaCy can struggle with ambiguous, recursive, or grammatically strange inputs. \"\n",
        "    \"NLTK may misclassify or repeat tags in repetitive phrases, while SpaCy often marks unknown or odd tokens as 'X'. \"\n",
        "    \"Social media text and technical terms are particularly difficult for both systems, highlighting the need for \"\n",
        "    \"domain-specific tuning and additional context handling.\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMSa1qZYGJn0",
        "outputId": "67175488-8b90-4478-93df-f7f9503a8b37"
      },
      "id": "xMSa1qZYGJn0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš¨ EDGE CASE ANALYSIS\n",
            "==================================================\n",
            "\n",
            "ðŸ” Edge Case 1:\n",
            "Text: Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\n",
            "------------------------------\n",
            "NLTK tags: [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('.', '.')]\n",
            "SpaCy tags: [('Buffalo', 'PROPN'), ('buffalo', 'NOUN'), ('Buffalo', 'PROPN'), ('buffalo', 'PROPN'), ('buffalo', 'PROPN'), ('buffalo', 'PROPN'), ('Buffalo', 'PROPN'), ('buffalo', 'PROPN'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 2:\n",
            "Text: Time flies like an arrow; fruit flies like a banana.\n",
            "------------------------------\n",
            "NLTK tags: [('Time', 'NNP'), ('flies', 'NNS'), ('like', 'IN'), ('an', 'DT'), ('arrow', 'NN'), (';', ':'), ('fruit', 'CC'), ('flies', 'NNS'), ('like', 'IN'), ('a', 'DT'), ('banana', 'NN'), ('.', '.')]\n",
            "SpaCy tags: [('Time', 'NOUN'), ('flies', 'VERB'), ('like', 'ADP'), ('an', 'DET'), ('arrow', 'NOUN'), (';', 'PUNCT'), ('fruit', 'NOUN'), ('flies', 'NOUN'), ('like', 'ADP'), ('a', 'DET'), ('banana', 'NOUN'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 3:\n",
            "Text: The man the boat the river.\n",
            "------------------------------\n",
            "NLTK tags: [('The', 'DT'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN'), ('the', 'DT'), ('river', 'NN'), ('.', '.')]\n",
            "SpaCy tags: [('The', 'DET'), ('man', 'NOUN'), ('the', 'DET'), ('boat', 'NOUN'), ('the', 'DET'), ('river', 'NOUN'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 4:\n",
            "Text: Police police Police police police police Police police.\n",
            "------------------------------\n",
            "NLTK tags: [('Police', 'NNP'), ('police', 'NNS'), ('Police', 'NNP'), ('police', 'NNS'), ('police', 'NN'), ('police', 'NN'), ('Police', 'NNP'), ('police', 'NNS'), ('.', '.')]\n",
            "SpaCy tags: [('Police', 'NOUN'), ('police', 'NOUN'), ('Police', 'NOUN'), ('police', 'NOUN'), ('police', 'NOUN'), ('police', 'NOUN'), ('Police', 'NOUN'), ('police', 'NOUN'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 5:\n",
            "Text: James while John had had had had had had had had had had had a better effect on the teacher.\n",
            "------------------------------\n",
            "NLTK tags: [('James', 'NNP'), ('while', 'IN'), ('John', 'NNP'), ('had', 'VBD'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('had', 'VBN'), ('a', 'DT'), ('better', 'RBR'), ('effect', 'NN'), ('on', 'IN'), ('the', 'DT'), ('teacher', 'NN'), ('.', '.')]\n",
            "SpaCy tags: [('James', 'PROPN'), ('while', 'SCONJ'), ('John', 'PROPN'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'AUX'), ('had', 'VERB'), ('a', 'DET'), ('better', 'ADJ'), ('effect', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('teacher', 'NOUN'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 6:\n",
            "Text: Can can can can can can can can can can.\n",
            "------------------------------\n",
            "NLTK tags: [('Can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('can', 'MD'), ('.', '.')]\n",
            "SpaCy tags: [('Can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'AUX'), ('can', 'VERB'), ('.', 'PUNCT')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ” Edge Case 7:\n",
            "Text: @username #hashtag http://bit.ly/abc123 ðŸ˜‚ðŸ”¥ðŸ’¯\n",
            "------------------------------\n",
            "NLTK tags: [('@', 'JJ'), ('username', 'JJ'), ('#', '#'), ('hashtag', 'JJ'), ('http', 'NN'), (':', ':'), ('//bit.ly/abc123', 'NN'), ('ðŸ˜‚ðŸ”¥ðŸ’¯', 'NN')]\n",
            "SpaCy tags: [('@username', 'PROPN'), ('#', 'SYM'), ('hashtag', 'NOUN'), ('http://bit.ly/abc123', 'PROPN'), ('ðŸ˜‚', 'PROPN'), ('ðŸ”¥', 'X'), ('ðŸ’¯', 'NOUN')]\n",
            "âš ï¸ Unusual tags detected:\n",
            "SpaCy X tags: ['ðŸ”¥']\n",
            "\n",
            "ðŸ” Edge Case 8:\n",
            "Text: COVID-19 AI/ML IoT APIs RESTful microservices\n",
            "------------------------------\n",
            "NLTK tags: [('COVID-19', 'JJ'), ('AI/ML', 'NNP'), ('IoT', 'NNP'), ('APIs', 'NNP'), ('RESTful', 'NNP'), ('microservices', 'NNS')]\n",
            "SpaCy tags: [('COVID-19', 'PROPN'), ('AI', 'PROPN'), ('/', 'SYM'), ('ML', 'PROPN'), ('IoT', 'ADJ'), ('APIs', 'NOUN'), ('RESTful', 'PART'), ('microservices', 'NOUN')]\n",
            "âœ… Taggers handled the input reasonably.\n",
            "\n",
            "ðŸ¤” REFLECTION ON LIMITATIONS:\n",
            "========================================\n",
            "Both NLTK and SpaCy can struggle with ambiguous, recursive, or grammatically strange inputs. NLTK may misclassify or repeat tags in repetitive phrases, while SpaCy often marks unknown or odd tokens as 'X'. Social media text and technical terms are particularly difficult for both systems, highlighting the need for domain-specific tuning and additional context handling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969fe260",
      "metadata": {
        "id": "969fe260"
      },
      "source": [
        "\n",
        "### ðŸ§  Critical Thinking Questions:\n",
        "Enter you asnwers below each question.\n",
        "1. Why do these edge cases break the taggers?\n",
        "\n",
        "2. How might you preprocess text to handle some of these issues?\n",
        "\n",
        "3. When would these limitations matter in real applications?\n",
        "\n",
        "4. How do modern large language models handle these cases differently?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa06861",
      "metadata": {
        "id": "4aa06861"
      },
      "source": [
        "\n",
        "## ðŸŽ¯ Final Reflection and Submission\n",
        "\n",
        "Congratulations! You've completed a comprehensive exploration of POS tagging, from basic concepts to real-world challenges.\n",
        "\n",
        "### ðŸ“ Reflection Questions (Answer in the cell below):\n",
        "\n",
        "1. **Tool Comparison**: Based on your experience, when would you choose NLTK vs SpaCy? Consider factors like ease of use, accuracy, speed, and application type.\n",
        "\n",
        "2. **Real-World Applications**: Describe a specific business problem where POS tagging would be valuable. How would you implement it?\n",
        "\n",
        "3. **Limitations and Solutions**: What are the biggest limitations you discovered? How might you work around them?\n",
        "\n",
        "4. **Future Learning**: What aspects of POS tagging would you like to explore further? (Neural approaches, custom training, domain adaptation, etc.)\n",
        "\n",
        "5. **Integration**: How does POS tagging fit into larger NLP pipelines? What other NLP tasks might benefit from POS information?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c5480f",
      "metadata": {
        "id": "b1c5480f"
      },
      "source": [
        "\n",
        "### âœï¸ Your Reflection (Write your answers here):\n",
        "**Remember Reflection is not description!**\n",
        "\n",
        "**1. Tool Comparison:**\n",
        "Based on my experience, I would choose SpaCy for most real-world applications due to its speed, ease of use, and modern architecture. It handles large datasets efficiently and provides cleaner, more readable outputs, especially for beginners. NLTK, on the other hand, is more educational and modular itâ€™s great for learning the underlying mechanics of POS tagging and for experimentation with tokenization or grammar rules. For simple scripts or rule-based systems, NLTK may still be useful, but for production environments, SpaCy is the better option in terms of both speed and accuracy.\n",
        "\n",
        "**2. Real-World Applications:**\n",
        "A specific business problem where POS tagging would be valuable is in automating customer service ticket triage. For instance, in a retail setting, incoming tickets could be analyzed using POS tagging to identify urgency and sentiment. Frequent use of verbs like â€œcancel,â€ â€œreturn,â€ or â€œbrokenâ€ combined with strong adjectives can signal high-priority issues. This could be implemented by combining a POS tagger like SpaCy with a keyword-sentiment classifier, allowing the system to route tickets to the appropriate department based on the problem type and emotional tone.\n",
        "\n",
        "**3. Limitations and Solutions:**\n",
        "One of the biggest limitations I discovered is that both NLTK and SpaCy struggle with informal or domain specific language, such as slang, social media text, or technical jargon. This can result in misclassifications, especially for ambiguous or abbreviated words. A potential workaround would be to preprocess the text more carefully for example, expanding contractions, removing emojis, or normalizing slang. Additionally, fine-tuning models on domain specific data or using newer transformer based models could help improve accuracy in such cases.\n",
        "\n",
        "**4. Future Learning:**\n",
        "In the future, Iâ€™d like to explore neural approaches to POS tagging, especially transformer based models like BERT that offer state of the art accuracy. Iâ€™m also interested in custom training and domain adaptation, where you can fine tune taggers for specialized tasks like medical text or legal documents. Learning how to build and train such models using frameworks like Hugging Face or spaCyâ€™s custom pipelines would be a valuable next step in advancing my NLP skills.\n",
        "\n",
        "**5. Integration:**\n",
        "POS tagging fits into larger NLP pipelines as a foundational step for many tasks. It supports named entity recognition (NER), dependency parsing, sentiment analysis, and even machine translation by helping to clarify grammatical roles in a sentence. For example, in information extraction, identifying verbs and nouns accurately allows systems to extract actions and entities from unstructured text. Overall, POS tagging acts as a bridge between raw text and more complex semantic understanding in NLP systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96f81e5",
      "metadata": {
        "id": "e96f81e5"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ðŸ“¤ Submission Checklist\n",
        "\n",
        "Before submitting your completed notebook, make sure you have:\n",
        "\n",
        "- [ ] âœ… Completed all TODO sections with working code\n",
        "- [ ] âœ… Answered all reflection questions thoughtfully\n",
        "- [ ] âœ… Created at least one meaningful visualization\n",
        "- [ ] âœ… Tested your code and fixed any errors\n",
        "- [ ] âœ… Added comments explaining your approach\n",
        "- [ ] âœ… Included insights from your analysis\n",
        "\n",
        "### ðŸ“‹ Submission Instructions:\n",
        "1. **Save your notebook**: File â†’ Save (or Ctrl+S)\n",
        "2. **Download**: File â†’ Download â†’ Download .ipynb\n",
        "3. **Submit**: Upload your completed notebook file to the course management system\n",
        "4. **Filename**: Use format: `L05_LastName_FirstName_ITAI2373.ipynb or pdf`  \n",
        "\n",
        "### ðŸ† Grading Criteria:\n",
        "- **Code Completion (40%)**: All exercises completed with working code\n",
        "- **Analysis Quality (30%)**: Thoughtful interpretation of results\n",
        "- **Reflection Depth (20%)**: Insightful answers to reflection questions  \n",
        "- **Code Quality (10%)**: Clean, commented, well-organized code\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ‰ Great Work!\n",
        "\n",
        "You've successfully explored the fascinating world of POS tagging! You now understand how computers parse human language and can apply these techniques to solve real-world problems.\n",
        "\n",
        "\n",
        "Keep exploring and happy coding! ðŸš€\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}